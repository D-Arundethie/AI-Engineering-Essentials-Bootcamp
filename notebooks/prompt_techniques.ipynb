{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e2d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..') # One step back from the currect direction\n",
    "\n",
    "from utils.prompts import render # Visualized the prompts\n",
    "from utils.llm_client import LLMClient # pick LLM Client\n",
    "from utils.logging_utils import log_llm_call # logging every API call\n",
    "from utils.router import pick_model, should_use_reasoning_model # General, reasoning or strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cbb33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\user\\\\Downloads\\\\ZUU CREW\\\\AI Engineer Essentials\\\\Codes\\\\Week 01\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce7ca8",
   "metadata": {},
   "source": [
    "### 01 - Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7581127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: gpt-4o-mini\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'The sentiment is: positive',\n",
       " 'usage': {'input_tokens_est': 47,\n",
       "  'context_tokens_est': 0,\n",
       "  'total_est': 50,\n",
       "  'prompt_tokens_actual': 50,\n",
       "  'completion_tokens_actual': 5,\n",
       "  'total_tokens_actual': 55},\n",
       " 'latency_ms': 2593,\n",
       " 'raw': ChatCompletion(id='chatcmpl-CsVTOvUrcrZUyaSswbMLo1qKHBQA4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The sentiment is: positive', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1767106730, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_3683ee3deb', usage=CompletionUsage(completion_tokens=5, prompt_tokens=50, total_tokens=55, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))),\n",
       " 'meta': {'retry_count': 0, 'backoff_ms_total': 0, 'overflow_handled': False}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text, spec = render(\n",
    "                        \"zero_shot.v1\",\n",
    "                        role = \"sentiment_analysis\",\n",
    "                        Instruction = \"Analyze the following text determine the sentiment as positive / negetive / neutral.\",\n",
    "                        constrains = \"The sentiment should be one of the following: positive, negetive, neutral.\",\n",
    "                        format = \"The sentiment is: {sentiment}\"\n",
    "                        )\n",
    "\n",
    "model = pick_model(\"openai\", \"general\") # Hard to pick general or reasoning but choose general because detecting sentiment is not that logical, it's mainly depends on the keywords.\n",
    "print(\"Selected model:\", model)\n",
    "llm = LLMClient(\"openai\", model)\n",
    "\n",
    "text = \"I'm really happy with the product! It's amazing!\"\n",
    "messages = [\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : f\"{prompt_text}\\n\\nReview: {text}\"\n",
    "            }\n",
    "]\n",
    "\n",
    "llm.chat(messages, temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32749e32",
   "metadata": {},
   "source": [
    "### 02 - Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908b5b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is: neutral  \n",
      "Explanation: User expresses that the product seems nice but indicates it is not suitable for them, leading to a neutral sentiment.\n"
     ]
    }
   ],
   "source": [
    "examples = \"\"\"\n",
    "Example 01:\n",
    "Review: I'm really happy with the product! It's amazing!\n",
    "Sentiment: positive\n",
    "Explanation: User says product is good also he is happy.\n",
    "\n",
    "Example 02:\n",
    "Review: I'm really unhappy with the product! It's bad!\n",
    "Sentiment: negetive\n",
    "Explanation: User says product is bad and he is unhappy.\n",
    "\n",
    "Example 03:\n",
    "Review: The product is okay, but It's not great.\n",
    "Sentiment: neutral\n",
    "Explanation: User says product is okay but not great.\n",
    "\n",
    "Example 04:\n",
    "Review: I'm not sure about the product.\n",
    "Sentiment: neutral\n",
    "Explanation: User is not sure about the product.\n",
    "\n",
    "Example 05:\n",
    "Review: I'm really happy with the product! It's bad!\n",
    "Sentiment: negetive\n",
    "Explanation: User says product is good but he is unhappy. So we are prioratizing his words on product quality, not his happiness. That's why we are considering the product quality as negative.\n",
    "\n",
    "Example 06:\n",
    "Review: I'm really unhappy with the product but It's amazing!\n",
    "Sentiment: positive\n",
    "Explanation: User says product is bad but he is happy. So we are prioratizing his words on product quality, not his happiness. That's why we are considering the product quality as positive.\n",
    "\"\"\"\n",
    "\n",
    "prompt_text, spec = render(\n",
    "                        \"few_shot.v1\",\n",
    "                        role = \"sentiment_analysis\", \n",
    "                        examples = examples,\n",
    "                        Instruction = \"Analyze the following text determine the sentiment as positive / negetive / neutral. Also provide the explanation for the sentiment.\",\n",
    "                        constrains = \"The sentiment should be one of the following: positive, negetive, neutral.\",\n",
    "                        format = \"The sentiment is: {sentiment}\"\n",
    "                        )\n",
    "\n",
    "model = pick_model(\"openai\", \"general\")\n",
    "llm = LLMClient(\"openai\", model)\n",
    "\n",
    "text = \"It seems nice but It's not for me.\"\n",
    "messages = [\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : f\"{prompt_text}\\n\\nReview: {text}\"\n",
    "            }\n",
    "]\n",
    "\n",
    "response = llm.chat(messages, temperature=0.0)\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b3f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7ad44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cb92b98",
   "metadata": {},
   "source": [
    "### 03 - COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02b88a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045d091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pick_model(\"google\",\"reason\")\n",
    "# llm = LLMClient(\"google\", model)\n",
    "\n",
    "# problem = \"\"\" \n",
    "#             A car travels 100 miles in 2 hours. What is the average speed of the car?\n",
    "#             also if car stops for 40 minutes what is the average speed of the car? \n",
    "#         \"\"\"\n",
    "\n",
    "# prompt_text, spec = render(\n",
    "#                             \"cot_reasoning.v1\",\n",
    "#                             role = \"math_tutor\",\n",
    "#                             Instruction = \"\"\" Solve the following problem step by step.\n",
    "#                                                 1. First identify whether car travelled the entire time without stopping or not.\n",
    "#                                                 2. If car stopped for x minutes and overall for y the travel duration is y-x.\n",
    "#                                             \"\"\",\n",
    "#                             problem = problem\n",
    "#                             )\n",
    "\n",
    "# messages = [\n",
    "#             {\n",
    "#                 \"role\" : \"user\",\n",
    "#                 \"content\" : f\"{prompt_text}\"\n",
    "#             }\n",
    "# ]\n",
    "\n",
    "# response = llm.chat(messages, temperature=0.3)\n",
    "# response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846fb3f",
   "metadata": {},
   "source": [
    "### 04 - TOT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
